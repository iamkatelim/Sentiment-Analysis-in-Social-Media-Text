{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title: Sentiment Analysis in Social Media Text using Neural Network <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "Description:\n",
    "\n",
    "In this project, two most frequently used machine learning algorithms, which are Multinomial NaÃ¯ve Bayes and Logistic Regression machine learning algorithm, are used to compare with the proposed method. \n",
    "\n",
    "To improve the performance of machine learning model, Stratified K-Fold cross validation is used to cross validate class imbalance dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Content\n",
    "\n",
    "* [Introduction](#intro)\n",
    "\t* [Set-up environment](#set_up)\n",
    "\t* [Load Dataset](#load_data)\n",
    "\t* [Drop Duplicate Rows](#drop_row)\n",
    "\t* [Categorical Target Conversion](#convert_target)\n",
    "* [Word Embedding - BOW](#word_emb)\n",
    "\t* [Logistic Regression + BOW](#bow_lr)\n",
    "* [Word Embedding - TF-IDF](#tfidf_emb)\n",
    "\t* [Naive Bayes + TF-IDF](#tfidf_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up Environment <a class=\"anchor\" id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## for data\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## for processing\n",
    "import re\n",
    "import nltk\n",
    "## for bag-of-words\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "## for explainer\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "## for bert language model\n",
    "import transformers\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset <a class=\"anchor\" id=\"load_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed</th>\n",
       "      <th>normalized</th>\n",
       "      <th>check</th>\n",
       "      <th>check_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210221</td>\n",
       "      <td>#dsnr salam dato.. lebih kurang 15km dari ruma...</td>\n",
       "      <td>negative</td>\n",
       "      <td>salam dato lebih kurang  km dari rumah ke kila...</td>\n",
       "      <td>salam dato lebih kurang km dari rumah ke kilan...</td>\n",
       "      <td>salam dato lebih kurang kkm dari rumah ke kila...</td>\n",
       "      <td>kurang kkm rumah ke kilang pkp pkb pkpp tidak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210204</td>\n",
       "      <td>#noorhishamabdullah youâ€™re not dr.fauci materi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>you re not dr fauci material you re just pn gr...</td>\n",
       "      <td>you re not dr fauci material you re just pun g...</td>\n",
       "      <td>you re not dr fauci material you re just pun g...</td>\n",
       "      <td>not fauci material grabmart boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210130</td>\n",
       "      <td>#share dan #like page #the_information_news un...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dan page untuk mendapatkan khabar berita yang ...</td>\n",
       "      <td>dan page untuk mendapatkan khabar berita yang ...</td>\n",
       "      <td>dan page untuk mendapatkan khabar berita yang ...</td>\n",
       "      <td>page khabar berita saudara patani selatan thai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210202</td>\n",
       "      <td>1 dunia sedang &amp; terus diperbodohkan dgn agend...</td>\n",
       "      <td>negative</td>\n",
       "      <td>satu dunia sedang and terus diperbodohkan dgn ...</td>\n",
       "      <td>satu dunia sedang and terus diperbodohkan deng...</td>\n",
       "      <td>satu dunia sedang and terus diperbodohkan deng...</td>\n",
       "      <td>dunia diperbodohkan agenda yahudi ekonomi duni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210206</td>\n",
       "      <td>1 hari sy harap angka nie turun single digit m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>satu hari sy harap angka nie turun single digi...</td>\n",
       "      <td>satu hari sy harap angka ini turun single digi...</td>\n",
       "      <td>satu hari sy harap angka ini turun single digi...</td>\n",
       "      <td>harap angka turun single digit capai zero case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>20210121</td>\n",
       "      <td>wish</td>\n",
       "      <td>positive</td>\n",
       "      <td>wish</td>\n",
       "      <td>wish</td>\n",
       "      <td>wish</td>\n",
       "      <td>wish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>20210123</td>\n",
       "      <td>ya allah.. sy rasa satu pkra kita terlepas pan...</td>\n",
       "      <td>positive</td>\n",
       "      <td>ya allah sy rasa satu pkra kita terlepas panda...</td>\n",
       "      <td>ya allah sy rasa satu pkra kita terlepas panda...</td>\n",
       "      <td>ya allah sy rasa satu pkra kita terlepas panda...</td>\n",
       "      <td>pkra terlepas pandang lupa solat hajat bacaan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>20210124</td>\n",
       "      <td>ya allah mari kita brdoa bnyk2 smoga allah amp...</td>\n",
       "      <td>positive</td>\n",
       "      <td>ya allah mari kita brdoa bnyk  smoga allah amp...</td>\n",
       "      <td>ya allah mari kita brdoa banyak semoga allah a...</td>\n",
       "      <td>ya allah mari kita berdoa banyak semoga allah ...</td>\n",
       "      <td>mari berdoa banyak semoga ampunkan dosa harap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>20210125</td>\n",
       "      <td>yaallah ya tuhan ku sembuhkan la semua pesakit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yaallah ya tuhan ku sembuhkan la semua pesakit...</td>\n",
       "      <td>yaal lah ya tuhan ku sembuhkan la semua pesaki...</td>\n",
       "      <td>yaal lah ya tuhan aku sembuhkan la semua pesak...</td>\n",
       "      <td>tuhan sembuhkan pesakit covid tuhan lindungi k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>20210121</td>\n",
       "      <td>ðŸ˜°more deaths. god have mercy ðŸ˜°</td>\n",
       "      <td>negative</td>\n",
       "      <td>more deaths god have mercy</td>\n",
       "      <td>more deaths god have mercy</td>\n",
       "      <td>more deaths god have mercy</td>\n",
       "      <td>deaths god mercy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7907 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                               text sentiment  \\\n",
       "0     20210221  #dsnr salam dato.. lebih kurang 15km dari ruma...  negative   \n",
       "1     20210204  #noorhishamabdullah youâ€™re not dr.fauci materi...  negative   \n",
       "2     20210130  #share dan #like page #the_information_news un...   neutral   \n",
       "3     20210202  1 dunia sedang & terus diperbodohkan dgn agend...  negative   \n",
       "4     20210206  1 hari sy harap angka nie turun single digit m...  positive   \n",
       "...        ...                                                ...       ...   \n",
       "7902  20210121                                               wish  positive   \n",
       "7903  20210123  ya allah.. sy rasa satu pkra kita terlepas pan...  positive   \n",
       "7904  20210124  ya allah mari kita brdoa bnyk2 smoga allah amp...  positive   \n",
       "7905  20210125  yaallah ya tuhan ku sembuhkan la semua pesakit...  positive   \n",
       "7906  20210121                     ðŸ˜°more deaths. god have mercy ðŸ˜°  negative   \n",
       "\n",
       "                                              processed  \\\n",
       "0     salam dato lebih kurang  km dari rumah ke kila...   \n",
       "1     you re not dr fauci material you re just pn gr...   \n",
       "2     dan page untuk mendapatkan khabar berita yang ...   \n",
       "3     satu dunia sedang and terus diperbodohkan dgn ...   \n",
       "4     satu hari sy harap angka nie turun single digi...   \n",
       "...                                                 ...   \n",
       "7902                                               wish   \n",
       "7903  ya allah sy rasa satu pkra kita terlepas panda...   \n",
       "7904  ya allah mari kita brdoa bnyk  smoga allah amp...   \n",
       "7905  yaallah ya tuhan ku sembuhkan la semua pesakit...   \n",
       "7906                         more deaths god have mercy   \n",
       "\n",
       "                                             normalized  \\\n",
       "0     salam dato lebih kurang km dari rumah ke kilan...   \n",
       "1     you re not dr fauci material you re just pun g...   \n",
       "2     dan page untuk mendapatkan khabar berita yang ...   \n",
       "3     satu dunia sedang and terus diperbodohkan deng...   \n",
       "4     satu hari sy harap angka ini turun single digi...   \n",
       "...                                                 ...   \n",
       "7902                                               wish   \n",
       "7903  ya allah sy rasa satu pkra kita terlepas panda...   \n",
       "7904  ya allah mari kita brdoa banyak semoga allah a...   \n",
       "7905  yaal lah ya tuhan ku sembuhkan la semua pesaki...   \n",
       "7906                         more deaths god have mercy   \n",
       "\n",
       "                                                  check  \\\n",
       "0     salam dato lebih kurang kkm dari rumah ke kila...   \n",
       "1     you re not dr fauci material you re just pun g...   \n",
       "2     dan page untuk mendapatkan khabar berita yang ...   \n",
       "3     satu dunia sedang and terus diperbodohkan deng...   \n",
       "4     satu hari sy harap angka ini turun single digi...   \n",
       "...                                                 ...   \n",
       "7902                                               wish   \n",
       "7903  ya allah sy rasa satu pkra kita terlepas panda...   \n",
       "7904  ya allah mari kita berdoa banyak semoga allah ...   \n",
       "7905  yaal lah ya tuhan aku sembuhkan la semua pesak...   \n",
       "7906                         more deaths god have mercy   \n",
       "\n",
       "                                             check_stop  \n",
       "0     kurang kkm rumah ke kilang pkp pkb pkpp tidak ...  \n",
       "1                       not fauci material grabmart boy  \n",
       "2     page khabar berita saudara patani selatan thai...  \n",
       "3     dunia diperbodohkan agenda yahudi ekonomi duni...  \n",
       "4     harap angka turun single digit capai zero case...  \n",
       "...                                                 ...  \n",
       "7902                                               wish  \n",
       "7903  pkra terlepas pandang lupa solat hajat bacaan ...  \n",
       "7904  mari berdoa banyak semoga ampunkan dosa harap ...  \n",
       "7905  tuhan sembuhkan pesakit covid tuhan lindungi k...  \n",
       "7906                                   deaths god mercy  \n",
       "\n",
       "[7907 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pd.read_csv('3 classes/facebook_health_cases (all).csv')\n",
    "df = pd.DataFrame(texts)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Duplicate Row(s) <a class=\"anchor\" id=\"drop_row\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaned:  (7907, 7)\n",
      "After:  (7905, 7)\n"
     ]
    }
   ],
   "source": [
    "# remove possible empty text cell\n",
    "print(\"before cleaned: \", df.shape)\n",
    "df['check_stop'].replace('', np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"After: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Target Conversion   <a class=\"anchor\" id=\"convert_target\"></a>\n",
    "\n",
    "*cat.codes* is a function from library Panda that convert categorical value to numeric value. In this project, the target values that has been converted are:\n",
    "- negative -> 0\n",
    "- neutral -> 1\n",
    "- positive -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the sentiment into 0 , 1, 2\n",
    "df['sentiment'] = df['sentiment'].map({'positive':2, 'negative':0, 'neutral':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check first five rows after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed</th>\n",
       "      <th>normalized</th>\n",
       "      <th>check</th>\n",
       "      <th>check_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210221</td>\n",
       "      <td>#dsnr salam dato.. lebih kurang 15km dari ruma...</td>\n",
       "      <td>0</td>\n",
       "      <td>salam dato lebih kurang  km dari rumah ke kila...</td>\n",
       "      <td>salam dato lebih kurang km dari rumah ke kilan...</td>\n",
       "      <td>salam dato lebih kurang kkm dari rumah ke kila...</td>\n",
       "      <td>kurang kkm rumah ke kilang pkp pkb pkpp tidak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210204</td>\n",
       "      <td>#noorhishamabdullah youâ€™re not dr.fauci materi...</td>\n",
       "      <td>0</td>\n",
       "      <td>you re not dr fauci material you re just pn gr...</td>\n",
       "      <td>you re not dr fauci material you re just pun g...</td>\n",
       "      <td>you re not dr fauci material you re just pun g...</td>\n",
       "      <td>not fauci material grabmart boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210130</td>\n",
       "      <td>#share dan #like page #the_information_news un...</td>\n",
       "      <td>1</td>\n",
       "      <td>dan page untuk mendapatkan khabar berita yang ...</td>\n",
       "      <td>dan page untuk mendapatkan khabar berita yang ...</td>\n",
       "      <td>dan page untuk mendapatkan khabar berita yang ...</td>\n",
       "      <td>page khabar berita saudara patani selatan thai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210202</td>\n",
       "      <td>1 dunia sedang &amp; terus diperbodohkan dgn agend...</td>\n",
       "      <td>0</td>\n",
       "      <td>satu dunia sedang and terus diperbodohkan dgn ...</td>\n",
       "      <td>satu dunia sedang and terus diperbodohkan deng...</td>\n",
       "      <td>satu dunia sedang and terus diperbodohkan deng...</td>\n",
       "      <td>dunia diperbodohkan agenda yahudi ekonomi duni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210206</td>\n",
       "      <td>1 hari sy harap angka nie turun single digit m...</td>\n",
       "      <td>2</td>\n",
       "      <td>satu hari sy harap angka nie turun single digi...</td>\n",
       "      <td>satu hari sy harap angka ini turun single digi...</td>\n",
       "      <td>satu hari sy harap angka ini turun single digi...</td>\n",
       "      <td>harap angka turun single digit capai zero case...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                                               text  sentiment  \\\n",
       "0  20210221  #dsnr salam dato.. lebih kurang 15km dari ruma...          0   \n",
       "1  20210204  #noorhishamabdullah youâ€™re not dr.fauci materi...          0   \n",
       "2  20210130  #share dan #like page #the_information_news un...          1   \n",
       "3  20210202  1 dunia sedang & terus diperbodohkan dgn agend...          0   \n",
       "4  20210206  1 hari sy harap angka nie turun single digit m...          2   \n",
       "\n",
       "                                           processed  \\\n",
       "0  salam dato lebih kurang  km dari rumah ke kila...   \n",
       "1  you re not dr fauci material you re just pn gr...   \n",
       "2  dan page untuk mendapatkan khabar berita yang ...   \n",
       "3  satu dunia sedang and terus diperbodohkan dgn ...   \n",
       "4  satu hari sy harap angka nie turun single digi...   \n",
       "\n",
       "                                          normalized  \\\n",
       "0  salam dato lebih kurang km dari rumah ke kilan...   \n",
       "1  you re not dr fauci material you re just pun g...   \n",
       "2  dan page untuk mendapatkan khabar berita yang ...   \n",
       "3  satu dunia sedang and terus diperbodohkan deng...   \n",
       "4  satu hari sy harap angka ini turun single digi...   \n",
       "\n",
       "                                               check  \\\n",
       "0  salam dato lebih kurang kkm dari rumah ke kila...   \n",
       "1  you re not dr fauci material you re just pun g...   \n",
       "2  dan page untuk mendapatkan khabar berita yang ...   \n",
       "3  satu dunia sedang and terus diperbodohkan deng...   \n",
       "4  satu hari sy harap angka ini turun single digi...   \n",
       "\n",
       "                                          check_stop  \n",
       "0  kurang kkm rumah ke kilang pkp pkb pkpp tidak ...  \n",
       "1                    not fauci material grabmart boy  \n",
       "2  page khabar berita saudara patani selatan thai...  \n",
       "3  dunia diperbodohkan agenda yahudi ekonomi duni...  \n",
       "4  harap angka turun single digit capai zero case...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the composition of the dataset, I am going to look into the univariate distribution of the target by showing labels frequency with a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.suptitle(\"sentiment\", fontsize=12)\n",
    "df[\"sentiment\"].reset_index().groupby(\"sentiment\").count().sort_values(by= \n",
    "       \"index\").plot(kind=\"barh\", legend=False, \n",
    "        ax=ax).grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split dataset\n",
    "# X = df.drop(['sentiment'], axis=1)\n",
    "# y = df.sentiment\n",
    "# dtf_train, dtf_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW and TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count (classic BoW)\n",
    "# vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "\n",
    "## Tf-Idf (advanced variant of BoW)\n",
    "#vectorizer = feature_extraction.text.TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "\n",
    "# both capture unigram and bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7905 entries, 0 to 7904\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   date        7905 non-null   int64 \n",
      " 1   text        7905 non-null   object\n",
      " 2   sentiment   7905 non-null   int64 \n",
      " 3   processed   7905 non-null   object\n",
      " 4   normalized  7905 non-null   object\n",
      " 5   check       7905 non-null   object\n",
      " 6   check_stop  7905 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 432.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lime Visualizer\n",
    "\n",
    "source: https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer + model evaluation + lime (all in one :D)\n",
    "def ml_plot(corpus, model, split_percent, limee=False): \n",
    "    X = corpus.check_stop\n",
    "    y = corpus.sentiment\n",
    "    \n",
    "    \n",
    "    # Create StratifiedKFold object.\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    lst_accu_stratified = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        vectorizer = feature_extraction.text.CountVectorizer(max_features=10000) #bigram\n",
    "        x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "        X_train = vectorizer.fit_transform(x_train_fold)\n",
    "        X_test = vectorizer.transform(x_test_fold)\n",
    "        clf = model\n",
    "        clf.fit(X_train, y_train_fold)\n",
    "        lst_accu_stratified.append(clf.score(X_test, y_test_fold))\n",
    "\n",
    "    #clf = model\n",
    "    #clf['classifier'].fit(X_train, y_train)\n",
    "    #prediction = clf.predict(X_test_ori)\n",
    "    #predicted_prob = clf.predict_proba(X_test_ori)\n",
    "    accuracy = np.array(lst_accu_stratified)\n",
    "    print('\\nMax Accuracy:', max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nAverage Accuracy:', np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression + BOW <a class=\"anchor\" id=\"bow_lr\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max Accuracy: 75.85335018963337 %\n",
      "\n",
      "Average Accuracy: 0.7447195506409129\n"
     ]
    }
   ],
   "source": [
    "ml_plot(df, LogisticRegression(max_iter=1000), .02, limee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer + model evaluation + lime (all in one :D)\n",
    "def ml_plot_tfidf(corpus, model, split_percent, limee=False): \n",
    "    X = corpus.check_stop\n",
    "    y = corpus.sentiment\n",
    "    \n",
    "    \n",
    "    # Create StratifiedKFold object.\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    lst_accu_stratified = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        vectorizer = feature_extraction.text.TfidfVectorizer(max_features=10000)\n",
    "        x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "        X_train = vectorizer.fit_transform(x_train_fold)\n",
    "        X_test = vectorizer.transform(x_test_fold)\n",
    "        clf = model\n",
    "        clf.fit(X_train, y_train_fold)\n",
    "        lst_accu_stratified.append(clf.score(X_test, y_test_fold))\n",
    "\n",
    "    #clf = model\n",
    "    #clf['classifier'].fit(X_train, y_train)\n",
    "    #prediction = clf.predict(X_test_ori)\n",
    "    #predicted_prob = clf.predict_proba(X_test_ori)\n",
    "    accuracy = np.array(lst_accu_stratified)\n",
    "    print('\\nMax Accuracy:', max(lst_accu_stratified)*100, '%')\n",
    "    print('\\nAverage Accuracy:', np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes + TF-IDF <a class=\"anchor\" id=\"tfidf_nb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max Accuracy: 73.79746835443038 %\n",
      "\n",
      "Average Accuracy: 0.7299198258893567\n"
     ]
    }
   ],
   "source": [
    "m = ml_plot_tfidf(df, MultinomialNB(), .02, limee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
